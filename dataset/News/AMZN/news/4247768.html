<!DOCTYPE html>
<html lang="en"><head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1,maximum-scale=5,minimum-scale=1,user-scalable=yes" name="viewport"/><title>Deep Learning’s Carbon Emissions Problem</title><link as="image" href="https://imageio.forbes.com/specials-images/imageserve/5eea37fddb3b680006a1e6bc/Data-center-/960x0.jpg?format=jpg&amp;width=960" rel="preload"/><link as="font" crossorigin="" href="https://i.forbesimg.com/assets/fonts/Schnyder/Schnyder-SDemi-Web.woff2" rel="preload" type="font/woff2"/><link as="font" crossorigin="" href="https://i.forbesimg.com/assets/fonts/Graphik/Graphik-Medium-Web.woff2" rel="preload" type="font/woff2"/><link href="https://i.forbesimg.com/48X48-F.png" rel="icon"/><link href="https://www.forbes.com/sites/robtoews/2020/06/17/deep-learnings-climate-change-problem/" itemprop="url" rel="canonical"/><link href="https://www.forbes.com/sites/robtoews/feed/" rel="alternate" title="Deep Learning’s Carbon Emissions Problem - RSS" type="application/rss+xml"/><link href="https://www.forbes.com/sites/robtoews/2020/06/17/deep-learnings-climate-change-problem/" itemprop="url" rel="canonical"/><meta content="no-referrer-when-downgrade" name="referrer"/><meta content="The “bigger is better” ethos that currently dominates the AI research agenda threatens to inflict major environmental damage in the years ahead." itemprop="description" name="description"/><meta content="big data,artificial intelligence,deep learning,climate change,carbon emissions,data centers,cloud computing" itemprop="keywords" name="keywords"/><meta content="big data,artificial intelligence,deep learning,climate change,carbon emissions,data centers,cloud computing" itemprop="keywords" name="news_keywords"/><meta content="Rob Toews" itemprop="author" name="author"/><meta content="Innovation" itemprop="articleChannel" property="article:channel"/><meta content="AI" itemprop="articleSection" property="article:section"/><meta content="https://www.forbes.com/ai/" property="article:section_url"/><meta content="blogAndPostId/blog/post/7537-5eea3199d570a00006d75619" property="article:id"/><meta content="2020-06-17" itemprop="datePublished" property="article:published"/><meta content="2024-06-04" itemprop="dateModified" property="article:modified"/><meta content="https://www.facebook.com/forbes" property="article:publisher"/><meta content="Rob Toews" property="article:author"/><meta content="Deep Learning’s Carbon Emissions Problem" property="og:title"/><meta content="Forbes" property="og:site_name"/><meta content="article" property="og:type"/><meta content="https://www.forbes.com/sites/robtoews/2020/06/17/deep-learnings-climate-change-problem/" property="og:url"/><meta content="https://imageio.forbes.com/specials-images/imageserve/5eea37fddb3b680006a1e6bc/0x0.jpg?format=jpg&amp;crop=1024,576,x0,y50,safe&amp;height=900&amp;width=1600&amp;fit=bounds" name="image" property="og:image"/><meta content="The “bigger is better” ethos that currently dominates the AI research agenda threatens to inflict major environmental damage in the years ahead." property="og:description"/><meta content="2024-06-04T02:16:58.041-04:00" property="og:updated_time"/><meta content="123694841080850" property="fb:app_id"/><meta content="app-id=588647136" property="apple-itunes-app"/><meta content="summary_large_image" name="twitter:card"/><meta content="@forbes" name="twitter:site"/><meta content="@_RobToews" name="twitter:creator"/><meta content="Deep Learning’s Carbon Emissions Problem" name="twitter:title"/><meta content="The “bigger is better” ethos that currently dominates the AI research agenda threatens to inflict major environmental damage in the years ahead." name="twitter:description"/><meta content="https://imageio.forbes.com/specials-images/imageserve/5eea37fddb3b680006a1e6bc/0x0.jpg?format=jpg&amp;crop=1024,576,x0,y50,safe&amp;height=600&amp;width=1200&amp;fit=bounds" itemprop="image" name="twitter:image"/><meta content="big data,artificial intelligence,deep learning,climate change,carbon emissions,data centers,cloud computing" itemprop="keywords" name="news_keywords"/><meta content="max-image-preview:large" name="robots"/></head><body><div class="main-content main-content--desktop-article main-content--universal-header"><header class="header universal-header"><div class="header" id="globalHeader"><header class="_5jL4nbZg" role="banner"><div class="nKfcv-Ux"><div class="dN9h-rXs"><div aria-label="Open Navigation Menu" class="USVF4LaM" role="button" tabindex="0"><svg class="hamburger_svg__fs-icon hamburger_svg__fs-icon--hamburger" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M20 6v2H4V6h16zm0 5v2H4v-2h16zm0 5v2H4v-2h16z" fill-rule="evenodd"></path></svg></div></div><div class="LE8pB25c"><a class="_5MfnUGiW newsLetterSubscriptionLink" href="https://account.forbes.com/newsletters" rel="noreferrer" target="_blank"><span class="tzX7W8zX">Subscribe To Newsletters</span><span class="jyxDkm4x"><svg class="envelope_svg__fs-icon envelope_svg__fs-icon--envelope" viewbox="0 0 15 15" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M13.667 2c0-.733-.6-1.333-1.333-1.333H1.667C.934.667.334 1.267.334 2v8c0 .733.6 1.333 1.333 1.333h10.667c.733 0 1.333-.6 1.333-1.333V2zm-1.332 0L7 5.333 1.668 2h10.667zm0 8H1.668V3.333l5.333 3.334 5.334-3.334V10z" fill-rule="evenodd"></path></svg></span></a></div></div><div class="ABr9cx9r"><div class="center"></div><a aria-label="Forbes Logo" class="_1NZmb47g" href="https://www.forbes.com/"><svg class="forbes-logo_svg__fs-icon forbes-logo_svg__fs-icon--forbes-logo" viewbox="0 0 200 54" xmlns="http://www.w3.org/2000/svg"><path d="M113.3 18.2c0-5.8.1-11.2.4-16.2L98.4 4.9v1.4l1.5.2c1.1.1 1.8.5 2.2 1.1.4.7.7 1.7.9 3.2.2 2.9.4 9.5.3 19.9 0 10.3-.1 16.8-.3 19.3 5.5 1.2 9.8 1.7 13 1.7 6 0 10.7-1.7 14.1-5.2 3.4-3.4 5.2-8.2 5.2-14.1 0-4.7-1.3-8.6-3.9-11.7-2.6-3.1-5.9-4.6-9.8-4.6-2.6 0-5.3.7-8.3 2.1zm.3 30.8c-.2-3.2-.4-12.8-.4-28.5.9-.3 2.1-.5 3.6-.5 2.4 0 4.3 1.2 5.7 3.7 1.4 2.5 2.1 5.5 2.1 9.3 0 4.7-.8 8.5-2.4 11.7-1.6 3.1-3.6 4.7-6.1 4.7-.8-.2-1.6-.3-2.5-.4zM41 3H1v2l2.1.2c1.6.3 2.7.9 3.4 1.8.7 1 1.1 2.6 1.2 4.8.8 10.8.8 20.9 0 30.2-.2 2.2-.6 3.8-1.2 4.8-.7 1-1.8 1.6-3.4 1.8l-2.1.3v2h25.8v-2l-2.7-.2c-1.6-.2-2.7-.9-3.4-1.8-.7-1-1.1-2.6-1.2-4.8-.3-4-.5-8.6-.5-13.7l5.4.1c2.9.1 4.9 2.3 5.9 6.7h2V18.9h-2c-1 4.3-2.9 6.5-5.9 6.6l-5.4.1c0-9 .2-15.4.5-19.3h7.9c5.6 0 9.4 3.6 11.6 10.8l2.4-.7L41 3zm-4.7 30.8c0 5.2 1.5 9.5 4.4 12.9 2.9 3.4 7.2 5 12.6 5s9.8-1.7 13-5.2c3.2-3.4 4.7-7.7 4.7-12.9s-1.5-9.5-4.4-12.9c-2.9-3.4-7.2-5-12.6-5s-9.8 1.7-13 5.2c-3.2 3.4-4.7 7.7-4.7 12.9zm22.3-11.4c1.2 2.9 1.7 6.7 1.7 11.3 0 10.6-2.2 15.8-6.5 15.8-2.2 0-3.9-1.5-5.1-4.5-1.2-3-1.7-6.8-1.7-11.3C47 23.2 49.2 18 53.5 18c2.2-.1 3.9 1.4 5.1 4.4zm84.5 24.3c3.3 3.3 7.5 5 12.5 5 3.1 0 5.8-.6 8.2-1.9 2.4-1.2 4.3-2.7 5.6-4.5l-1-1.2c-2.2 1.7-4.7 2.5-7.6 2.5-4 0-7.1-1.3-9.2-4-2.2-2.7-3.2-6.1-3-10.5H170c0-4.8-1.2-8.7-3.7-11.8-2.5-3-6-4.5-10.5-4.5-5.6 0-9.9 1.8-13 5.3-3.1 3.5-4.6 7.8-4.6 12.9 0 5.2 1.6 9.4 4.9 12.7zm7.4-25.1c1.1-2.4 2.5-3.6 4.4-3.6 3 0 4.5 3.8 4.5 11.5l-10.6.2c.1-3 .6-5.7 1.7-8.1zm46.4-4c-2.7-1.2-6.1-1.9-10.2-1.9-4.2 0-7.5 1.1-10 3.2s-3.8 4.7-3.8 7.8c0 2.7.8 4.8 2.3 6.3 1.5 1.5 3.9 2.8 7 3.9 2.8 1 4.8 2 5.8 2.9 1 1 1.6 2.1 1.6 3.6 0 1.4-.5 2.7-1.6 3.7-1 1.1-2.4 1.6-4.2 1.6-4.4 0-7.7-3.2-10-9.6l-1.7.5.4 10c3.6 1.4 7.6 2.1 12 2.1 4.6 0 8.1-1 10.7-3.1 2.6-2 3.9-4.9 3.9-8.5 0-2.4-.6-4.4-1.9-5.9-1.3-1.5-3.4-2.8-6.4-4-3.3-1.2-5.6-2.3-6.8-3.3-1.2-1-1.8-2.2-1.8-3.7s.4-2.7 1.3-3.7 2-1.4 3.4-1.4c4 0 6.9 2.9 8.7 8.6l1.7-.5-.4-8.6zm-96.2-.9c-1.4-.7-2.9-1-4.6-1-1.7 0-3.4.7-5.3 2.1-1.9 1.4-3.3 3.3-4.4 5.9l.1-8-15.2 3v1.4l1.5.1c1.9.2 3 1.7 3.2 4.4.6 6.2.6 12.8 0 19.8-.2 2.7-1.3 4.1-3.2 4.4l-1.5.2v1.9h21.2V49l-2.7-.2c-1.9-.2-3-1.7-3.2-4.4-.6-5.8-.7-12-.2-18.4.6-1 1.9-1.6 3.9-1.8 2-.2 4.3.4 6.7 1.8l3.7-9.3z"></path></svg></a></div><div class="wOXWlwEZ"><nav class="qWN3kcjB"><a aria-label="Search" class="K8E0pmcH _00AX4IpY" href="https://www.forbes.com/search/" type="button"><svg class="search_svg__fs-icon search_svg__fs-icon--search" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 14C7 14 5 12 5 9.5S7 5 9.5 5 14 7 14 9.5 12 14 9.5 14zm6 0h-.8l-.3-.3c1-1.1 1.6-2.6 1.6-4.2C16 5.9 13.1 3 9.5 3S3 5.9 3 9.5 5.9 16 9.5 16c1.6 0 3.1-.6 4.2-1.6l.3.3v.8l5 5 1.5-1.5-5-5z"></path></svg><svg class="sparkles_svg__fs-icon sparkles_svg__fs-icon--sparkles" fill="currentcolor" viewbox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M11.755 14.214a5.055 5.055 0 00-.954-1.39 5.06 5.06 0 00-1.346-.983c.513-.24.972-.548 1.373-.933.405-.391.734-.846.995-1.36.244.521.558.985.952 1.388a5 5 0 001.345.973 5.04 5.04 0 00-1.375.943 5.043 5.043 0 00-.99 1.362zM5.21 4.128a3.414 3.414 0 00-.973.948 3.422 3.422 0 00-.946-.976 3.39 3.39 0 00.974-.944 3.38 3.38 0 00.945.972z" stroke="currentcolor" stroke-width="1.5"></path></svg></a></nav></div></header></div></header><div class="beta-flag beta-flag-hidden"><div class="beta-flag-label"><div class="beta-flag-info-icon"><svg class="fs-icon fs-icon--info" viewbox="0 0 60 60" xmlns="http://www.w3.org/2000/svg"><path d="M28.3 38.4h3.3v-10h-3.3v10zM30 13.3c-9.2 0-16.7 7.5-16.7 16.7S20.8 46.7 30 46.7 46.7 39.2 46.7 30 39.2 13.3 30 13.3zm0 30.1c-7.4 0-13.4-6-13.4-13.4s6-13.4 13.4-13.4 13.4 6 13.4 13.4-6 13.4-13.4 13.4zM28.3 25h3.3v-3.3h-3.3V25z" fill="#010101"></path></svg></div><div class="beta-flag-text">BETA</div></div><div class="beta-flag-info">THIS IS A BETA EXPERIENCE. OPT-OUT <span>HERE</span><div class="beta-close-icon"><svg class="fs-icon fs-icon--close" viewbox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M2 9h16v2H2z" transform="rotate(45.001 10 10)"></path><path d="M2 9h16v2H2z" transform="rotate(134.999 10 10)"></path></svg></div></div></div><article class="pay-wall-content content_5eea3199d570a00006d75619 current-page" id="article-container-0"><fbs-ad ad-id="ntv-contentd" batched="" class="ntv-contentd" position="ntv-contentd"></fbs-ad><div class="top-ad-container fbs-ad--top-wrapper top-ad__individual-content top-ad__hide-label"><div class="top-stories"><h3 class="preview__eyebrows preview__eyebrows--top-stories"><span data-ga-track="Top Stories Label">More From Forbes</span></h3><div class="top-stories__carousel-wrapper"><fbs-carousel class="top-stories__carousel fbs-slider _9g15eeqf4mfc00 fbs-slider--initialized" data-fbs-carousel-config-id="_9g15eeqf4mfc00"><div class="fbs-slider__slides-wrapper"><div class="fbs-slider__slides" style="width: 100%; transform: translateX(0px);"><div aria-hidden="false" class="fbs-slider__slide active primary" data-fbs-carousel-slide-id="c6g5ohb3cq0000" tabindex="0"><div class="top-stories-img-container"><div class="top-stories-img-placeholder ratio16x9"><a aria-hidden="false" class="top-stories-img" data-ga-track="Top Story 1" data-index="1" href="https://www.forbes.com/sites/janetnovack/2024/11/16/forbes-post-election-investment-guide-protect-your-wealth/" style="background-image:url(https://specials-images.forbesimg.com/imageserve/6738077b16362bb7257691ba/0x0.jpg)" tabindex="0"></a></div></div><div class="top-stories__date"><time>Nov 16, 2024,</time><span class="time"><time>07:30am EST</time></span></div><a aria-hidden="false" class="top-stories__title" data-ga-track="Top Story 1" data-index="1" href="https://www.forbes.com/sites/janetnovack/2024/11/16/forbes-post-election-investment-guide-protect-your-wealth/" tabindex="0">Forbes Post-Election Investment Guide: Protect Your Wealth</a></div><div aria-hidden="false" class="fbs-slider__slide active" data-fbs-carousel-slide-id="f8lfp7jgj72o00" tabindex="0"><div class="top-stories-img-container"><div class="top-stories-img-placeholder ratio16x9"><a aria-hidden="false" class="top-stories-img" data-ga-track="Top Story 2" data-index="2" href="https://www.forbes.com/sites/lanceeliot/2024/11/18/ai-is-now-co-creator-of-our-collective-intelligence-so-watch-your-back/" style="background-image:url(https://specials-images.forbesimg.com/imageserve/673c077e68f99a1faaee67d8/290x0.jpg?cropX1=158&amp;cropX2=3614&amp;cropY1=0&amp;cropY2=2304)" tabindex="0"></a></div></div><div class="top-stories__date"><time>Nov 18, 2024,</time><span class="time"><time>10:46pm EST</time></span></div><a aria-hidden="false" class="top-stories__title" data-ga-track="Top Story 2" data-index="2" href="https://www.forbes.com/sites/lanceeliot/2024/11/18/ai-is-now-co-creator-of-our-collective-intelligence-so-watch-your-back/" tabindex="0">AI Is Now Co-Creator Of Our Collective Intelligence So Watch Your Back</a></div><div aria-hidden="false" class="fbs-slider__slide active" data-fbs-carousel-slide-id="46l655r87o4c00" tabindex="0"><div class="top-stories-img-container"><div class="top-stories-img-placeholder ratio16x9"><a aria-hidden="false" class="top-stories-img" data-ga-track="Top Story 3" data-index="3" href="https://www.forbes.com/sites/johnwerner/2024/11/18/what-should-you-know-about-yi-34b/" style="background-image:url(https://specials-images.forbesimg.com/imageserve/673ba3ce008b33a3a7aeaa1b/290x0.jpg)" tabindex="0"></a></div></div><div class="top-stories__date"><time>Nov 18, 2024,</time><span class="time"><time>03:32pm EST</time></span></div><a aria-hidden="false" class="top-stories__title" data-ga-track="Top Story 3" data-index="3" href="https://www.forbes.com/sites/johnwerner/2024/11/18/what-should-you-know-about-yi-34b/" tabindex="0">What Should You Know About Yi-34B?</a></div><div aria-hidden="false" class="fbs-slider__slide active" data-fbs-carousel-slide-id="e576ok240gdo00" tabindex="0"><div class="top-stories-img-container"><div class="top-stories-img-placeholder ratio16x9"><a aria-hidden="false" class="top-stories-img" data-ga-track="Top Story 4" data-index="4" href="https://www.forbes.com/sites/torconstantino/2024/11/18/claude-ai-demo-makes-e-commerce-buys---violating-its-training/" style="background-image:url(https://specials-images.forbesimg.com/imageserve/673b8b84daf0f7bcb0e42ef1/290x0.jpg)" tabindex="0"></a></div></div><div class="top-stories__date"><time>Nov 18, 2024,</time><span class="time"><time>02:38pm EST</time></span></div><a aria-hidden="false" class="top-stories__title" data-ga-track="Top Story 4" data-index="4" href="https://www.forbes.com/sites/torconstantino/2024/11/18/claude-ai-demo-makes-e-commerce-buys---violating-its-training/" tabindex="0">Claude AI Demo Makes E-Commerce Buy — Violating Its Training Or Not?</a></div><div aria-hidden="false" class="fbs-slider__slide active" data-fbs-carousel-slide-id="f43340cbep5k00" tabindex="0"><div class="top-stories-img-container"><div class="top-stories-img-placeholder ratio16x9"><a aria-hidden="false" class="top-stories-img" data-ga-track="Top Story 5" data-index="5" href="https://www.forbes.com/sites/chuckbrooks/2024/11/18/5-cybersecurity-priorities-for-the-trump-administration/" style="background-image:url(https://specials-images.forbesimg.com/imageserve/673b782a208126628450ed73/290x0.jpg)" tabindex="0"></a></div></div><div class="top-stories__date"><time>Nov 18, 2024,</time><span class="time"><time>12:50pm EST</time></span></div><a aria-hidden="false" class="top-stories__title" data-ga-track="Top Story 5" data-index="5" href="https://www.forbes.com/sites/chuckbrooks/2024/11/18/5-cybersecurity-priorities-for-the-trump-administration/" tabindex="0">5 Cybersecurity Priorities for The Trump Administration</a></div><div aria-hidden="false" class="fbs-slider__slide active" data-fbs-carousel-slide-id="d0cd4ch4m6lo00" tabindex="0"><div class="top-stories-img-container"><div class="top-stories-img-placeholder ratio16x9"><a aria-hidden="false" class="top-stories-img" data-ga-track="Top Story 6" data-index="6" href="https://www.forbes.com/sites/ericsiegel/2024/11/18/predictive-ai-usually-fails-because-its-not-usually-valuated/" style="background-image:url(https://specials-images.forbesimg.com/imageserve/673b6b45cf25fcebab92452f/290x0.jpg)" tabindex="0"></a></div></div><div class="top-stories__date"><time>Nov 18, 2024,</time><span class="time"><time>11:35am EST</time></span></div><a aria-hidden="false" class="top-stories__title" data-ga-track="Top Story 6" data-index="6" href="https://www.forbes.com/sites/ericsiegel/2024/11/18/predictive-ai-usually-fails-because-its-not-usually-valuated/" tabindex="0">Predictive AI Usually Fails Because It’s Not Usually Valuated</a></div><div aria-hidden="true" class="fbs-slider__slide" data-fbs-carousel-slide-id="384fag2kg2oc00" tabindex="-1"><div class="top-stories-img-container"><div class="top-stories-img-placeholder ratio16x9"><a aria-hidden="true" class="top-stories-img" data-ga-track="Top Story 7" data-index="7" href="https://www.forbes.com/sites/lanceeliot/2024/11/17/evolving-together-human-ai-coevolution-is-said-to-be-coming-whether-humanity-likes-it-or-not/" style="background-image:url(https://specials-images.forbesimg.com/imageserve/673aafff715b5d548a22f667/290x0.jpg)" tabindex="-1"></a></div></div><div class="top-stories__date"><time>Nov 17, 2024,</time><span class="time"><time>10:16pm EST</time></span></div><a aria-hidden="true" class="top-stories__title" data-ga-track="Top Story 7" data-index="7" href="https://www.forbes.com/sites/lanceeliot/2024/11/17/evolving-together-human-ai-coevolution-is-said-to-be-coming-whether-humanity-likes-it-or-not/" tabindex="-1">Evolving Together: Human-AI Coevolution Is Said To Be Coming Whether Humanity Likes It Or Not</a></div><div aria-hidden="true" class="fbs-slider__slide" data-fbs-carousel-slide-id="2cpdejakqmlg00" tabindex="-1"><div class="top-stories-img-container"><div class="top-stories-img-placeholder ratio16x9"><a aria-hidden="true" class="top-stories-img" data-ga-track="Top Story 8" data-index="8" href="https://www.forbes.com/sites/hamiltonmann/2024/11/17/in-ai-businesses-trust-but-are-still-accountable-for-integrity-lapses/" style="background-image:url(https://specials-images.forbesimg.com/imageserve/673a554a252e09af44c96306/290x0.jpg)" tabindex="-1"></a></div></div><div class="top-stories__date"><time>Nov 17, 2024,</time><span class="time"><time>03:55pm EST</time></span></div><a aria-hidden="true" class="top-stories__title" data-ga-track="Top Story 8" data-index="8" href="https://www.forbes.com/sites/hamiltonmann/2024/11/17/in-ai-businesses-trust-but-are-still-accountable-for-integrity-lapses/" tabindex="-1">In AI Businesses Trust—But Are Still Accountable For Integrity Lapses</a></div><div aria-hidden="true" class="fbs-slider__slide" data-fbs-carousel-slide-id="2gclrifq9o3o00" tabindex="-1"><div class="top-stories-img-container"><div class="top-stories-img-placeholder ratio16x9"><a aria-hidden="true" class="top-stories-img" data-ga-track="Top Story 9" data-index="9" href="https://www.forbes.com/sites/johnwerner/2024/11/17/sam-altman-speaks-on-tech-progress/" style="background-image:url(https://specials-images.forbesimg.com/imageserve/66f480ffb26f62218c8f166c/290x0.jpg)" tabindex="-1"></a></div></div><div class="top-stories__date"><time>Nov 17, 2024,</time><span class="time"><time>09:39am EST</time></span></div><a aria-hidden="true" class="top-stories__title" data-ga-track="Top Story 9" data-index="9" href="https://www.forbes.com/sites/johnwerner/2024/11/17/sam-altman-speaks-on-tech-progress/" tabindex="-1">Sam Altman Speaks On Tech Progress</a></div></div></div><div class="fbs-slider__controls"><button aria-label="Arrow Left" class="fbs-slider__control-left fbs-slider__control--hidden fbs-slider__foucs disabled" data-ga-track="More from Forbes Block - Carousel Previous"><svg class="fs-icon fs-icon--arrow-left" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 5l-7 7 7 7 1.4-1.4L6.8 13H21v-2H6.8l4.6-4.6z"></path></svg></button><button aria-label="Arrow Right" class="fbs-slider__control-right disabled" data-ga-track="More from Forbes Block - Carousel Next"><svg class="fs-icon fs-icon--arrow-right" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12.6 6.4l4.6 4.6H3v2h14.2l-4.6 4.6L14 19l7-7-7-7z"></path></svg></button></div></fbs-carousel></div></div><fbs-ad ad-id="article-0-top" batched="" position="top"></fbs-ad></div><main class="main-content--body" id="article-stream-0"><div class="edit-story-container hide-button"><a class="edit-story-call" href="https://bertie.forbes.com/#/compose?id=5eea3199d570a00006d75619" rel="noopener noreferrer" role="button" target="_blank"><svg class="fs-icon fs-icon--edit" viewbox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M16.2 1C17.7 1 19 2.3 19 3.8c0 .6-.2 1.2-.6 1.7l-1.1 1.1-3.9-3.9 1.1-1.1c.5-.4 1.1-.6 1.7-.6zM2.1 13.9L1 19l5.1-1.1L16.5 7.5l-3.9-3.9L2.1 13.9zm11.5-6.5l-7.9 7.9-1-1 7.9-7.9 1 1z" fill="#030303"></path></svg><span>Edit Story</span></a></div><div class="article-wrapper"><div article-index="0" class="left-rail"></div><div class="middleRightRail"><div class="body-container"><div class="article-headline-container"><div class="header-content-container"><div class="breadCrumb-container"><div class="_8cjw-SPU fTSKiIOA"><span class="_6Q2IDc-r"><a class="isDg-4PG" data-ga-track="breadcrumb-L1" href="https://www.forbes.com/">Forbes</a></span><span class="_6Q2IDc-r"><span class="KChd-Vju" data-testid="separator"><svg class="chevron-right_svg__fs-icon chevron-right_svg__fs-icon--chevron-right" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.2 7.2L13 12l-4.8 4.8 1.5 1.4L16 12 9.7 5.8z"></path></svg></span><a class="isDg-4PG" data-ga-track="breadcrumb-L2" href="https://www.forbes.com/innovation/">Innovation</a></span><span class="_6Q2IDc-r"><span class="KChd-Vju" data-testid="separator"><svg class="chevron-right_svg__fs-icon chevron-right_svg__fs-icon--chevron-right" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.2 7.2L13 12l-4.8 4.8 1.5 1.4L16 12 9.7 5.8z"></path></svg></span><a class="isDg-4PG" data-ga-track="breadcrumb-L3" href="https://www.forbes.com/ai/">AI</a></span></div></div><div class="top-label-wrapper"></div><h1 class="fs-headline speakable-headline font-base font-size fs-headline__standard">Deep Learning’s Carbon Emissions Problem</h1></div></div><div class="top-contrib-block" style="border-color: "><div class="contribs"><div class="contrib-container top-contrib bottom-padding"><div class="fs-author-group-wrapper"><div class="contrib-byline has-follow-button"><div class="fs-author-wrapper"><span class="fs-author-name"><a aria-label="Rob Toews" class="contrib-link--name remove-underline author-name--tracking not-premium-contrib-link--name" data-ga-track="contrib block byline" href="https://www.forbes.com/sites/robtoews/" title="https://www.forbes.com/sites/robtoews/">Rob Toews</a><div class="contrib-label-container"><span class="contrib-byline-type">Contributor</span><span class="disclaimer"><svg class="fs-icon fs-icon--info" viewbox="0 0 60 60" xmlns="http://www.w3.org/2000/svg"><path d="M28.3 38.4h3.3v-10h-3.3v10zM30 13.3c-9.2 0-16.7 7.5-16.7 16.7S20.8 46.7 30 46.7 46.7 39.2 46.7 30 39.2 13.3 30 13.3zm0 30.1c-7.4 0-13.4-6-13.4-13.4s6-13.4 13.4-13.4 13.4 6 13.4 13.4-6 13.4-13.4 13.4zM28.3 25h3.3v-3.3h-3.3V25z" fill="#010101"></path></svg><div class="ftc-disclaimer__tooltip">Opinions expressed by Forbes Contributors are their own.</div></span></div></span></div><div class="short-bio"><span>I write about the big picture of artificial intelligence.</span></div></div><fbs-cordial author-slug="robtoews" natural-id="blogAuthorId/blog/author/3342587" page-position="top" type="Follow"><a aria-label="Following" class="following-label" href="https://account.forbes.com/following" target="blank" title="https://account.forbes.com/following"><svg class="fs-icon fs-icon--check-mark" viewbox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M10 2.9c-3.9 0-7.1 3.2-7.1 7.1s3.2 7.1 7.1 7.1 7.1-3.2 7.1-7.1-3.2-7.1-7.1-7.1zm-.7 10.3l-3-2.1.7-1 2 1.4 3.4-4.9 1 .7-4.1 5.9z" fill-rule="evenodd"></path></svg><span>Following</span></a></fbs-cordial></div></div><div class="metrics-channel light-text metrics-standard-topline with-border"><div class="anchors-container"><div class="save-article-wrapper" data-naturalid="blogAndPostId/blog/post/7537-5eea3199d570a00006d75619" data-uri="https://www.forbes.com/sites/robtoews/2020/06/17/deep-learnings-climate-change-problem/"></div><div class="for-you-popup"></div><div class="with-border-share-icon"><svg class="fs-icon fs-icon--share" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M18 16.1c-.8 0-1.4.3-2 .8l-7.1-4.2c.1-.2.1-.5.1-.7s0-.5-.1-.7L16 7.2c.5.5 1.2.8 2 .8 1.7 0 3-1.3 3-3s-1.3-3-3-3-3 1.3-3 3c0 .2 0 .5.1.7L8 9.8C7.5 9.3 6.8 9 6 9c-1.7 0-3 1.3-3 3s1.3 3 3 3c.8 0 1.5-.3 2-.8l7.1 4.2c-.1.2-.1.4-.1.6 0 1.6 1.3 2.9 2.9 2.9s2.9-1.3 2.9-2.9-1.2-2.9-2.8-2.9z" fill-rule="evenodd"></path></svg></div><div class="open-web-placeholder"></div></div><div class="content-data metrics-text color-body light-text standard-metrics-text"><time>Jun 17, 2020,</time><span class="time"><time>11:54am EDT</time></span></div></div><div class="updated-timestamp">Updated Dec 10, 2021, 09:41am EST</div></div></div><div class="article-body-container"><div class="elderly-label"><div class="elderly-clock"><span><svg class="fs-icon fs-icon--clock" viewbox="-5 -5 30 30" xmlns="http://www.w3.org/2000/svg"><path d="M12.5 7H11v6l5.2 3.1.8-1.2-4.5-2.7V7zM12 20c-4.4 0-8-3.6-8-8s3.6-8 8-8 8 3.6 8 8-3.6 8-8 8zm0-18C6.5 2 2 6.5 2 12s4.5 10 10 10 10-4.5 10-10S17.5 2 12 2z"></path></svg></span></div><span>This article is more than 4 years old.</span></div><div class="article-body fs-article fs-responsive-text current-article"><div class="article-sharing"><ul class="article-sharing__container" style="flex-direction: column;"><li class="article-sharing__item"><a aria-label="Share Facebook" class="social-icon color-change facebook" data-ga-track="Facebook Click" onclick="window.open(&quot;https://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.forbes.com%2Fsites%2Frobtoews%2F2020%2F06%2F17%2Fdeep-learnings-climate-change-problem%2F&quot;, 'window', 'width=400,height=500')" role="link"><span class="screen-reader-text">Share to Facebook</span><svg class="fs-icon fs-icon--Facebook" style="transform:scale(.9)" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M22 12c0-5.5-4.5-10-10-10S2 6.5 2 12c0 5 3.7 9.1 8.4 9.9v-7H7.9V12h2.5V9.8c0-2.5 1.5-3.9 3.8-3.9 1.1 0 2.2.2 2.2.2v2.5h-1.3c-1.2 0-1.6.8-1.6 1.6V12h2.8l-.4 2.9h-2.3v7C18.3 21.1 22 17 22 12z" fill-rule="evenodd"></path></svg></a></li><li class="article-sharing__item"><a aria-label="Share Twitter" class="social-icon color-change twitter" data-ga-track="Twitter Click" onclick="window.open(&quot;https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.forbes.com%2Fsites%2Frobtoews%2F2020%2F06%2F17%2Fdeep-learnings-climate-change-problem%2F&amp;text=Deep%20Learning%E2%80%99s%20Carbon%20Emissions%20Problem%20via%20%40forbes&quot;, 'window', 'width=400,height=500')" role="link"><span class="screen-reader-text">Share to Twitter</span><svg class="fs-icon fs-icon--xCorp" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path class="fs-icon fs-icon--XCorp" d="M16.6 5h2.454l-5.36 6.126L20 19.462h-4.937l-3.867-5.055-4.425 5.055H4.316l5.733-6.552L4 5h5.063l3.495 4.621L16.601 5zm-.86 12.994h1.36L8.323 6.391H6.865l8.875 11.603z"></path></svg></a></li><li class="article-sharing__item"><a aria-label="Share Linkedin" class="social-icon color-change linkedin" data-ga-track="Linkedin Click" onclick="window.open(&quot;https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fwww.forbes.com%2Fsites%2Frobtoews%2F2020%2F06%2F17%2Fdeep-learnings-climate-change-problem%2F&amp;title=Deep%20Learning%E2%80%99s%20Carbon%20Emissions%20Problem&amp;summary=The%20%E2%80%9Cbigger%20is%20better%E2%80%9D%20ethos%20that%20currently%20dominates%20the%20AI%20research%20agenda%20threatens%20to%20inflict%20major%20environmental%20damage%20in%20the%20years%20ahead.&quot;, 'window', 'width=400,height=500')" role="link"><span class="screen-reader-text">Share to Linkedin</span><svg class="fs-icon fs-icon--linkedin" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M7.6 20H4.4V9.4h3.4V20h-.2zM6 8c-1 0-2-.8-2-2s.8-2 2-2c1 0 2 .8 2 2S7 8 6 8zm14 12h-3.2v-5.6c0-1.6-.602-2.4-1.801-2.4-1.4 0-2 .8-2 2.4V20h-3.2V9.4h3.2v1.4s1-1.8 3.2-1.8 3.8 1.4 3.8 4.2V20z"></path></svg></a></li></ul></div><figure class="embed-base image-embed embed-0" role="presentation"><div class="image-embed__placeholder" style="padding-top:66.67%;position:relative"><progressive-image alt="Data center." data-height="683" data-width="1024" src="https://specials-images.forbesimg.com/imageserve/5eea37fddb3b680006a1e6bc/Data-center-/960x0.jpg?fit=scale"></progressive-image></div><figcaption><fbs-accordion><p class="color-body light-text">The human brain is an incredibly efficient source of intelligence. Today's AI is not.</p></fbs-accordion><small>Getty Images/iStockphoto</small></figcaption></figure>
<p>Earlier this month, OpenAI <a aria-label="announced" class="color-link" data-ga-track="ExternalLink:https://venturebeat.com/2020/05/29/openai-debuts-gigantic-gpt-3-language-model-with-175-billion-parameters/" href="https://venturebeat.com/2020/05/29/openai-debuts-gigantic-gpt-3-language-model-with-175-billion-parameters/" rel="nofollow noopener noreferrer" target="_blank" title="https://venturebeat.com/2020/05/29/openai-debuts-gigantic-gpt-3-language-model-with-175-billion-parameters/">announced</a> it had built the biggest AI model in history. This astonishingly large model, known as GPT-3, is an impressive technical achievement. Yet it highlights a troubling and harmful trend in the field of artificial intelligence—one that has not gotten enough mainstream attention.</p>
<div class="halfway_hardwall_1"></div>
<div class="article_paragraph_2"></div>
<p>Modern AI models consume a massive amount of energy, and these energy requirements are growing at a breathtaking rate. In the deep learning era, the computational resources needed to produce a best-in-class AI model has on average doubled <a aria-label="every 3.4 months" class="color-link" data-ga-track="ExternalLink:https://openai.com/blog/ai-and-compute/" href="https://openai.com/blog/ai-and-compute/" rel="nofollow noopener noreferrer" target="_blank" title="https://openai.com/blog/ai-and-compute/">every 3.4 months</a>; this translates to a 300,000x increase between 2012 and 2018. GPT-3 is just the latest embodiment of this exponential trajectory.</p>
<div class="halfway_hardwall_2"></div>
<p>The bottom line: AI has a meaningful carbon footprint today, and if industry trends continue it will soon become much worse. Unless we are willing to reassess and reform today’s AI research agenda, the field of artificial intelligence could become an antagonist in the fight against climate change in the years ahead.</p>
<div class="halfway_hardwall_3"></div>
<div class="vestpocket" vest-pocket=""></div>
<p><br/></p>
<div class="halfway_hardwall_4"></div>
<p><br/></p><fbs-ad ad-id="article-0-inread" aria-hidden="true" position="inread" progressive="" role="presentation"></fbs-ad>
<h3>Bigger Is Not Always Better</h3>
<p>In today’s deep learning-centric research paradigm, advances in artificial intelligence are primarily achieved through sheer scale: bigger datasets, larger models, more compute.</p>
<div class="recirc-module marketPlace" data-type="standard"><div class="recirc-module-body" id="recirc-unit"><div class="recirc-module-title">MORE FROM<span style="color:#395BB6;">FORBES ADVISOR</span></div><div class="recirc-articles"><div class="recirc-block-padding"><div class="recirc-content"><a aria-label="Best High-Yield Savings Accounts Of 2024" class="recirc-link" data-ga-track="Advisor Recirc - Multiple Articles - Link 1" href="https://www.forbes.com/advisor/banking/savings/best-high-yield-savings-accounts/?utm_source=forbes&amp;utm_medium=recirc&amp;utm_campaign=tiger-sept23" target="_self" title="https://www.forbes.com/advisor/banking/savings/best-high-yield-savings-accounts/?utm_source=forbes&amp;utm_medium=recirc&amp;utm_campaign=tiger-sept23"><h3 class="recirc-headline-no-margin" data-ga-track="Advisor Recirc - Multiple Articles - Link 1">Best High-Yield Savings Accounts Of 2024</h3></a><a aria-label="By Kevin Payne Contributor" class="recirc-author" href="https://www.forbes.com/advisor/author/kevin-payne/" target="_self" title="https://www.forbes.com/advisor/author/kevin-payne/">By<div class="recirc-author-name">Kevin Payne</div><div class="recirc-author-type">Contributor</div></a></div><a aria-label="Graphic Best High-Yield Savings Accounts Of 2024" class="recirc-img" data-ga-track="Advisor Recirc - Multiple Articles - Link 1" href="https://www.forbes.com/advisor/banking/savings/best-high-yield-savings-accounts/?utm_source=forbes&amp;utm_medium=recirc&amp;utm_campaign=tiger-sept23" style="background-image:url(https://thumbor.forbes.com/thumbor/fit-in/1290x/https://www.forbes.com/advisor/wp-content/uploads/2020/12/getty_1-best-online-savings-thumbnail_101920pm.jpg);"></a></div><div class="recirc-block-padding"><div class="recirc-content"><a aria-label="Best 5% Interest Savings Accounts of 2024" class="recirc-link" data-ga-track="Advisor Recirc - Multiple Articles - Link 2" href="https://www.forbes.com/advisor/banking/savings/best-5-percent-interest-savings-accounts/?utm_source=forbes&amp;utm_medium=recirc&amp;utm_campaign=tiger-sept23" target="_self" title="https://www.forbes.com/advisor/banking/savings/best-5-percent-interest-savings-accounts/?utm_source=forbes&amp;utm_medium=recirc&amp;utm_campaign=tiger-sept23"><h3 class="recirc-headline-no-margin" data-ga-track="Advisor Recirc - Multiple Articles - Link 2">Best 5% Interest Savings Accounts of 2024</h3></a><a aria-label="By Cassidy Horton Contributor" class="recirc-author" href="https://www.forbes.com/advisor/author/cassidy-horton" target="_self" title="https://www.forbes.com/advisor/author/cassidy-horton">By<div class="recirc-author-name">Cassidy Horton</div><div class="recirc-author-type">Contributor</div></a></div><a aria-label="Graphic Best 5% Interest Savings Accounts of 2024" class="recirc-img" data-ga-track="Advisor Recirc - Multiple Articles - Link 2" href="https://www.forbes.com/advisor/banking/savings/best-5-percent-interest-savings-accounts/?utm_source=forbes&amp;utm_medium=recirc&amp;utm_campaign=tiger-sept23" style="background-image:url(https://thumbor.forbes.com/thumbor/fit-in/900x510/https://www.forbes.com/advisor/wp-content/uploads/2023/09/Saving-Rates-2.jpg);"></a></div></div></div></div>
<p>GPT-3 illustrates this phenomenon well. The model consists of a whopping 175 billion parameters. To put this figure in perspective, its predecessor model GPT-2—which was considered state-of-the-art when it was released last year—had only 1.5 billion parameters. While last year’s GPT-2 took a few dozen petaflop-days to train—already a massive amount of computational input—GPT-3 required <a aria-label="several thousand." class="color-link" data-ga-track="ExternalLink:https://arxiv.org/pdf/2005.14165.pdf" href="https://arxiv.org/pdf/2005.14165.pdf" rel="nofollow noopener noreferrer" target="_blank" title="https://arxiv.org/pdf/2005.14165.pdf">several thousand.</a></p>
<div class="article_paragraph_7"></div>
<p>The problem with relying on ever-larger models to drive progress in AI is that building and deploying these models entails a tremendous amount of energy expenditure and thus carbon emissions.</p>
<p>In a widely discussed <a aria-label="2019 study" class="color-link" data-ga-track="ExternalLink:https://arxiv.org/pdf/1906.02243.pdf" href="https://arxiv.org/pdf/1906.02243.pdf" rel="nofollow noopener noreferrer" target="_blank" title="https://arxiv.org/pdf/1906.02243.pdf">2019 study</a>, a group of researchers led by Emma Strubell estimated that training a single deep learning model can generate up to 626,155 pounds of CO<sub>2</sub> emissions—roughly equal to the total lifetime carbon footprint of five cars. As a point of comparison, the average American generates 36,156 pounds of CO<sub>2</sub> emissions in a year.</p>


<p>To be sure, this estimate is for a particularly energy-intensive model. Training an average-sized machine learning model today generates far less than 626,155 pounds of carbon output.</p>
<p>At the same time, it is worth keeping in mind that when this analysis was conducted, GPT-2 was the largest model available for study and was treated by the researchers as an upper bound on model size. Just a year later, GPT-2 looks tiny—one hundred times smaller, in fact—compared to its successor.</p>
<p>Why exactly do machine learning models consume so much energy?</p>
<p>The first reason is that the datasets used to train these models <a aria-label="continue to balloon" class="color-link" data-ga-track="ExternalLink:https://arxiv.org/pdf/1907.10597.pdf" href="https://arxiv.org/pdf/1907.10597.pdf" rel="nofollow noopener noreferrer" target="_blank" title="https://arxiv.org/pdf/1907.10597.pdf">continue to balloon</a> in size. In 2018, the BERT model achieved best-in-class NLP performance after it was trained on a dataset of 3 billion words. XLNet outperformed BERT based on a training set of 32 billion words. Shortly thereafter, GPT-2 was trained on a dataset of 40 billion words. Dwarfing all these previous efforts, a weighted dataset of roughly 500 billion words was used to train GPT-3.</p>
<p>Neural networks carry out a lengthy set of mathematical operations (both forward propagation and back propagation) for each piece of data they are fed during training, updating their parameters in complex ways. Larger datasets therefore translate to soaring compute and energy requirements.</p>
<p>Another factor driving AI’s massive energy draw is the extensive experimentation and tuning required to develop a model. Machine learning today remains largely an exercise in trial and error. Practitioners will often build hundreds of versions of a given model during training, experimenting with different neural architectures and hyperparameters before identifying an optimal design.</p>
<p>The 2019 paper mentioned above includes a telling case study. The researchers picked an average-sized model—much smaller than headline-grabbing behemoths like GPT-3—and examined not just the energy required to train the final version, but the total number of trial runs that went into producing that final version.</p>
<p>Over the course of six months, 4,789 different versions of the model were trained, requiring 9,998 total days’ worth of GPU time (more than 27 years). Taking all these runs into account, the researchers estimated that building this model <a aria-label="generated" class="color-link" data-ga-track="ExternalLink:https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/" href="https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/" rel="nofollow noopener noreferrer" target="_blank" title="https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/">generated</a> over 78,000 pounds of CO<sub>2</sub> emissions in total—more than the average American adult will produce in two years.</p>
<p>To this point, the discussion has only addressed <em>training</em> machine learning models. But training is just the beginning of a model’s lifecycle. After a model is trained, it is then put to use in the real world.</p>
<p>Deploying AI models to take action in real-world settings—a process known as inference—consumes <a aria-label="even more energy" class="color-link" data-ga-track="ExternalLink:https://towardsdatascience.com/deep-learning-and-carbon-emissions-79723d5bc86e" href="https://towardsdatascience.com/deep-learning-and-carbon-emissions-79723d5bc86e" rel="nofollow noopener noreferrer" target="_blank" title="https://towardsdatascience.com/deep-learning-and-carbon-emissions-79723d5bc86e">even more energy</a> than training does. Indeed, Nvidia <a aria-label="estimates" class="color-link" data-ga-track="InternalLink:https://www.forbes.com/sites/moorinsights/2019/05/09/google-cloud-doubles-down-on-nvidia-gpus-for-inference/#244ad92a6792" href="https://www.forbes.com/sites/moorinsights/2019/05/09/google-cloud-doubles-down-on-nvidia-gpus-for-inference/#244ad92a6792" target="_self" title="https://www.forbes.com/sites/moorinsights/2019/05/09/google-cloud-doubles-down-on-nvidia-gpus-for-inference/#244ad92a6792">estimates</a> that 80% to 90% of the cost of a neural network is in inference rather than training.</p>
<p>As an example, consider the AI underlying an autonomous vehicle. The neural networks first must be trained upfront to learn to drive. After training is completed and the autonomous vehicle is deployed, the model then performs inference on a continuous basis in order to navigate its environment—nonstop, day after day, for as long as the vehicle is in use.</p>
<p>Needless to say, the more parameters the model has, the steeper the energy requirements are for this ongoing inference.</p>
<p><br/></p>
<h3>Energy Use and Carbon Emissions</h3>
<p>An assumption at the heart of this topic is the relationship between AI’s energy use and carbon emissions. What is the best way to think about this relationship?</p>
<p>According to the EPA, one kilowatt-hour of energy consumption <a aria-label="generates" class="color-link" data-ga-track="ExternalLink:https://www.epa.gov/energy/emissions-generation-resource-integrated-database-egrid" href="https://www.epa.gov/energy/emissions-generation-resource-integrated-database-egrid" rel="nofollow noopener noreferrer" target="_blank" title="https://www.epa.gov/energy/emissions-generation-resource-integrated-database-egrid">generates</a> 0.954 pounds of CO<sub>2</sub> emissions on average in the United States. This average reflects the varying carbon footprints and relative proportions of different electricity sources across the U.S. energy grid (e.g., renewables, nuclear, natural gas, coal).</p>
<p>Strubell’s analysis, mentioned above, applies this U.S.-wide average in order to calculate the carbon emissions of various AI models based on their energy needs. It is a reasonable assumption. The power source mix for Amazon Web Services, for instance, roughly mirrors that of the U.S. as a whole, and most AI models are trained in the cloud.</p>
<p>Of course, if an AI model were trained using electricity generated primarily from renewables, then its carbon footprint would be correspondingly lower. For instance, Google Cloud Platform’s power mix is more heavily weighted toward renewables than is AWS’ (56% v. 17%, according to the Strubell paper).</p>
<p>Or, to give another example, a model that is trained on hardware located in the Pacific Northwest would generate less carbon output than the national average because of the abundant clean hydropower <a aria-label="in that region" class="color-link" data-ga-track="ExternalLink:https://www.energy.gov/maps/renewable-energy-production-state" href="https://www.energy.gov/maps/renewable-energy-production-state" rel="nofollow noopener noreferrer" target="_blank" title="https://www.energy.gov/maps/renewable-energy-production-state">in that region</a>. And it is worth mentioning that every cloud provider touts its investments in <a aria-label="carbon offsets" class="color-link" data-ga-track="ExternalLink:https://www.wired.com/story/amazon-google-microsoft-green-clouds-and-hyperscale-data-centers/" href="https://www.wired.com/story/amazon-google-microsoft-green-clouds-and-hyperscale-data-centers/" rel="nofollow noopener noreferrer" target="_blank" title="https://www.wired.com/story/amazon-google-microsoft-green-clouds-and-hyperscale-data-centers/">carbon offsets</a>.</p>
<p>But taken in the aggregate, applying the overall U.S. power mix as Strubell does should yield a roughly accurate approximation of AI models’ carbon footprints.</p>
<p><br/></p>
<h3>Diminishing Returns</h3>
<p>The problem with chasing progress in AI via ever-larger models is highlighted by the relationship between model size and model performance. The data here is clear: increases in model size eventually exhibit sharply diminishing returns to performance.</p>
<p>An <a aria-label="illustrative example" class="color-link" data-ga-track="ExternalLink:https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035" href="https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035" rel="nofollow noopener noreferrer" target="_blank" title="https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035">illustrative example</a> will help make this point. ResNet was a well-known computer vision model released in 2015. An improved iteration of the model, known as ResNeXt, came out in 2017. ResNeXt required 35% more computational resources to train than did ResNet (measured by total floating point operations)—and achieved a 0.5% improvement in accuracy.</p>
<p>A <a aria-label="2019 paper" class="color-link" data-ga-track="ExternalLink:https://arxiv.org/pdf/1907.10597.pdf" href="https://arxiv.org/pdf/1907.10597.pdf" rel="nofollow noopener noreferrer" target="_blank" title="https://arxiv.org/pdf/1907.10597.pdf">2019 paper</a> from the Allen Institute for AI provides detailed data documenting the diminishing returns to model size across different tasks, models, and AI subfields. The most recent mega-model released, GPT-3, <a aria-label="displays" class="color-link" data-ga-track="ExternalLink:https://www.zdnet.com/article/openais-gigantic-gpt-3-hints-at-the-limits-of-language-models-for-ai/" href="https://www.zdnet.com/article/openais-gigantic-gpt-3-hints-at-the-limits-of-language-models-for-ai/" rel="nofollow noopener noreferrer" target="_blank" title="https://www.zdnet.com/article/openais-gigantic-gpt-3-hints-at-the-limits-of-language-models-for-ai/">displays</a> clear signs of diminishing returns compared to GPT-2.</p>
<p>If the AI community continues down its current path, greater and greater amounts of energy will need to be expended to build larger and larger models—in order to achieve ever-smaller incremental improvements in performance. Any cost/benefit analysis becomes increasingly disproportionate.</p>
<p>Given these diminishing returns, what motivates the continued development of ever-larger models? One major reason is the AI community’s current fixation on achieving “state-of-the-art” results on <a aria-label="performance benchmarks" class="color-link" data-ga-track="ExternalLink:https://super.gluebenchmark.com/leaderboard?fbclid=IwAR0zfW77f7R2teFGvbMI4fZzHHdy35reFF9A9a6b25rtZ87UT212x4wpmAo" href="https://super.gluebenchmark.com/leaderboard?fbclid=IwAR0zfW77f7R2teFGvbMI4fZzHHdy35reFF9A9a6b25rtZ87UT212x4wpmAo" rel="nofollow noopener noreferrer" target="_blank" title="https://super.gluebenchmark.com/leaderboard?fbclid=IwAR0zfW77f7R2teFGvbMI4fZzHHdy35reFF9A9a6b25rtZ87UT212x4wpmAo">performance benchmarks</a>. Building a model that sets a new accuracy record on a well-known benchmark—even if the improvement is only a fraction of a percent—can earn researchers recognition and acclaim.</p>
<p>As UCLA professor Guy Van den Broeck <a aria-label="put it" class="color-link" data-ga-track="ExternalLink:https://venturebeat.com/2020/06/01/ai-machine-learning-openai-gpt-3-size-isnt-everything/" href="https://venturebeat.com/2020/06/01/ai-machine-learning-openai-gpt-3-size-isnt-everything/" rel="nofollow noopener noreferrer" target="_blank" title="https://venturebeat.com/2020/06/01/ai-machine-learning-openai-gpt-3-size-isnt-everything/">put it</a>: “I think the best analogy is with some oil-rich country being able to build a very tall skyscraper. Sure, a lot of money and engineering effort goes into building these things. And you do get the ‘state of the art’ in building tall buildings. But…there is no scientific advancement per se.”</p>
<p>The “bigger is better” ethos that currently dominates the AI research agenda threatens to inflict major environmental damage in the years ahead. Thoughtful, bold change is needed to set the field of artificial intelligence on a more sustainable and productive trajectory.</p>
<p><br/></p>
<h3>Looking Forward</h3>
<p>To start, there are near-term “quick wins” that every AI practitioner should consider to mitigate the carbon impact of their research.</p>
<p>An important first step is to increase transparency and measurement on this issue. When AI researchers publish results for new models, they should include—alongside performance and accuracy metrics—data on how much energy was expended in model development.</p>
<p>In a thoughtful analysis, the team from the Allen Institute for AI <a aria-label="proposed" class="color-link" data-ga-track="ExternalLink:https://arxiv.org/pdf/1907.10597.pdf" href="https://arxiv.org/pdf/1907.10597.pdf" rel="nofollow noopener noreferrer" target="_blank" title="https://arxiv.org/pdf/1907.10597.pdf">proposed</a> floating point operations as the most universal and useful energy efficiency metric for researchers to track. Another group created a <a aria-label="Maching Learning Emissions Calculator" class="color-link" data-ga-track="ExternalLink:https://mlco2.github.io/impact/#compute" href="https://mlco2.github.io/impact/#compute" rel="nofollow noopener noreferrer" target="_blank" title="https://mlco2.github.io/impact/#compute">Maching Learning Emissions Calculator</a> that practitioners can use to estimate the carbon footprints of the models they build (based on factors including hardware, cloud provider, and geographical region).</p>
<p>Along these lines, it should become best practice for researchers to plot energy costs against performance gains when training models. Explicitly quantifying this tradeoff will prompt researchers to make more informed, balanced decisions about resource allocation in light of diminishing returns.</p>
<p>Hopefully, as sustainable AI practices spread, the community will begin to take efficiency metrics like these into account when evaluating AI research, just as it does today with traditional performance metrics like accuracy: for conference paper submissions, speaking opportunities, academic roles and so forth.</p>
<p>There is other <a aria-label="low-hanging fruit" class="color-link" data-ga-track="ExternalLink:https://arxiv.org/pdf/1910.09700.pdf" href="https://arxiv.org/pdf/1910.09700.pdf" rel="nofollow noopener noreferrer" target="_blank" title="https://arxiv.org/pdf/1910.09700.pdf">low-hanging fruit</a> that can help reduce AI’s carbon footprint in the near term: using more efficient hyperparameter search methods, reducing the number of unnecessary experiments during training, employing more energy-efficient hardware.</p>
<p>But by themselves, these remedial actions are not enough to solve the problem. A more fundamental long-term shift is needed in the field of artificial intelligence.</p>
<p>We need to take a step back and acknowledge that simply building ever-larger neural networks is not the right path to generalized intelligence. From first principles, we need to push ourselves to discover more elegant, efficient ways to model intelligence in machines. Our ongoing battle with climate change, and thus the future of our planet, depend on it.</p>
<p>To <a aria-label="quote" class="color-link" data-ga-track="ExternalLink:https://www.axios.com/artificial-intelligence-pioneer-says-we-need-to-start-over-1513305524-f619efbd-9db0-4947-a9b2-7a4c310a28fe.html" href="https://www.axios.com/artificial-intelligence-pioneer-says-we-need-to-start-over-1513305524-f619efbd-9db0-4947-a9b2-7a4c310a28fe.html" rel="nofollow noopener noreferrer" target="_blank" title="https://www.axios.com/artificial-intelligence-pioneer-says-we-need-to-start-over-1513305524-f619efbd-9db0-4947-a9b2-7a4c310a28fe.html">quote</a> AI legend Geoff Hinton, the godfather of deep learning: “The future depends on some graduate student who is deeply suspicious of everything I have said....My view is throw it all away and start again.”</p>
<p>The AI community must begin to work toward new paradigms in artificial intelligence that do not require exponentially growing datasets nor outrageously vast energy expenditures. Emerging research areas like <a aria-label="few-shot learning" class="color-link" data-ga-track="InternalLink:https://www.forbes.com/sites/robtoews/2019/11/04/questioning-the-long-term-importance-of-big-data-in-ai/#563bdd4e2177" href="https://www.forbes.com/sites/robtoews/2019/11/04/questioning-the-long-term-importance-of-big-data-in-ai/#563bdd4e2177" target="_self" title="https://www.forbes.com/sites/robtoews/2019/11/04/questioning-the-long-term-importance-of-big-data-in-ai/#563bdd4e2177">few-shot learning</a> are promising avenues.</p>
<p>The human brain—that original source of intelligence—provides important inspiration here. Our brains are incredibly efficient relative to today’s deep learning methods. They weigh a few pounds and require <a aria-label="about 20 watts" class="color-link" data-ga-track="ExternalLink:https://hypertextbook.com/facts/2001/JacquelineLing.shtml" href="https://hypertextbook.com/facts/2001/JacquelineLing.shtml" rel="nofollow noopener noreferrer" target="_blank" title="https://hypertextbook.com/facts/2001/JacquelineLing.shtml">about 20 watts</a> of energy, barely enough to power a dim lightbulb. Yet they represent the most powerful form of intelligence in the known universe.</p>
<p>“Human brains can do amazing things with little power consumption,” as AI researcher Siva Reddy <a aria-label="put it" class="color-link" data-ga-track="ExternalLink:https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/" href="https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/" rel="nofollow noopener noreferrer" target="_blank" title="https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/">put it</a>. “The question is how can we build such machines.”</p>
<div class="newsletter_signup_article"></div></div><div class="sigfile article-body fs-responsive-text"><span>Follow me on</span><a href="https://www.twitter.com/_RobToews" rel="nofollow noopener noreferrer" target="_blank">Twitter</a>. </div><div class="bottom-contrib-block"><div class="fs-author-group-wrapper"><div class="contrib-byline"><a class="fs-author-avatar" href="https://www.forbes.com/sites/robtoews/" title="Photo of Rob Toews"><img alt="Rob Toews" class="fs-author-image" src="https://specials-images.forbesimg.com/imageserve/6240c083d52f72212d14d789/400x0.jpg?cropX1=219&amp;cropX2=849&amp;cropY1=152&amp;cropY2=782"/></a><div class="contrib-info"><div class="author-wrapper"><a aria-label="Rob Toews" class="author-name contrib-byline-author speakable-author" data-ga-track="contrib block byline" href="https://www.forbes.com/sites/robtoews/" title="https://www.forbes.com/sites/robtoews/">Rob Toews</a></div></div></div><fbs-cordial author-slug="robtoews" natural-id="blogAuthorId/blog/author/3342587" page-position="bottom" type="Follow"><a aria-label="Following" class="following-label" href="https://account.forbes.com/following" target="blank" title="https://account.forbes.com/following"><svg class="fs-icon fs-icon--check-mark" viewbox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M10 2.9c-3.9 0-7.1 3.2-7.1 7.1s3.2 7.1 7.1 7.1 7.1-3.2 7.1-7.1-3.2-7.1-7.1-7.1zm-.7 10.3l-3-2.1.7-1 2 1.4 3.4-4.9 1 .7-4.1 5.9z" fill-rule="evenodd"></path></svg><span>Following</span></a></fbs-cordial></div><p class="contrib-bio" data-author-html-description="&lt;p&gt;Rob Toews is a venture capitalist at Radical Ventures.&lt;/p&gt;"></p></div><div class="article-footer" style="border:;"><ul class="footer-row color-body light-text print-tips"><li><a href="https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/" rel="noopener noreferrer" target="_blank">Editorial Standards</a></li><li><a href="https://www.parsintl.com/publications/forbes/" rel="noopener noreferrer" target="_blank">Forbes Accolades</a></li></ul><div aria-hidden="true" class="footer-ad-labeling" tabindex="-1"></div></div></div></div><div article-index="0" class="right-rail"><div class="ad-rail"><div class="fbs-ad-wrapper fbs-ad--article-0-rec-wrapper recx-alignment"><fbs-ad ad-id="article-0-rec" batched="" position="rec"></fbs-ad></div><div class="fbs-ad-wrapper fbs-ad--article-0-recx-1-wrapper recx-alignment"><fbs-ad ad-id="article-0-recx-1" batched="" position="recx"></fbs-ad></div></div></div></div></div><div aria-hidden="true" class="mnet-box article-wrapper" role="presentation" tabindex="-1"><div class="medianet-wrapper ad-unit mnet-btf"><div class="medianet fbs-ad--media_net_1_article_0-wrapper" data-params="" data-position="media_net_1_article_0" data-size="800x650" data-tagid="265256887"></div></div></div><div class="xl-recirc-ad"></div></main></article><div class="load-stream-marker"></div><div class="paywall_ribbon"></div><div id="onsite-notifications"></div></div></body></html>