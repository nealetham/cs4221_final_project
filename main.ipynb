{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from pathlib import Path\n",
    "import json\n",
    "import gzip\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from collections import defaultdict\n",
    "\n",
    "import io\n",
    "from datetime import datetime\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up of TimescaleDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"password\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_NAME = \"postgres\"\n",
    "\n",
    "CONNECTION_URL = f\"postgres://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_exec(sql, log=\"SQL executed successfully.\"):\n",
    "    try:\n",
    "        with psycopg2.connect(CONNECTION_URL) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(sql)\n",
    "        conn.commit()\n",
    "        print(f\"{log}\")\n",
    "    except Exception as e:\n",
    "        logging.error('Error at %s', 'division', exc_info=e)\n",
    "        print(f\"\\nSQL executed unsuccessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUSTRY table dropped successfully.\n",
      "SYMBOL table dropped successfully.\n",
      "OHLC table dropped successfully.\n"
     ]
    }
   ],
   "source": [
    "tables = [\"industry\", \"symbol\", \"ohlc\"]\n",
    "for table in tables:\n",
    "    db_exec(f\"DROP TABLE IF EXISTS {table} CASCADE\", f\"{table.upper()} table dropped successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHLC table created successfully\n"
     ]
    }
   ],
   "source": [
    "create_ohlc_table = \"\"\"CREATE TABLE IF NOT EXISTS ohlc (\n",
    "    symbol VARCHAR(10) NOT NULL,\n",
    "    industry VARCHAR(50),\n",
    "    timestamp TIMESTAMP NOT NULL,\n",
    "    open DECIMAL(10,2),\n",
    "    high DECIMAL(10,2),\n",
    "    low DECIMAL(10,2),\n",
    "    close DECIMAL(10,2)\n",
    ");\n",
    "\"\"\"\n",
    "db_exec(create_ohlc_table, \"OHLC table created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"./dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILE_PATH = os.path.join(BASE_DIR, \"profile_estimate\", \"profile.json\")\n",
    "\n",
    "def extract_symbol_industry():\n",
    "    symbol_industry = defaultdict(str)\n",
    "    with open(PROFILE_PATH, \"r\") as file:\n",
    "        company_profiles = json.load(file)\n",
    "        for symbol, profile in company_profiles.items():\n",
    "            symbol_industry[symbol] = profile[0][\"industry\"]\n",
    "    return symbol_industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHLC_DIR = os.path.join(BASE_DIR, \"OHLC\")\n",
    "\n",
    "symbol_industry = extract_symbol_industry()\n",
    "\n",
    "def insert_ohlc(symbol):\n",
    "    symbol_path = os.path.join(OHLC_DIR, symbol)\n",
    "    new_keys = {\"symbol\": symbol, \"industry\": symbol_industry[symbol]}\n",
    "\n",
    "    ohlc_buffer = io.StringIO()\n",
    "    \n",
    "    for date in os.listdir(symbol_path):\n",
    "        file_path = os.path.join(symbol_path, date)\n",
    "        with gzip.open(file_path, \"rt\") as file:\n",
    "            reader = csv.DictReader(file, delimiter=\",\")\n",
    "            for entry in reader:\n",
    "                row = (\n",
    "                    f\"{new_keys['symbol']},\"\n",
    "                    f\"{new_keys['industry']},\"\n",
    "                    f\"{datetime.fromtimestamp(int(entry['timestamp']))},\"\n",
    "                    f\"{float(entry['open'])},\"\n",
    "                    f\"{float(entry['high'])},\"\n",
    "                    f\"{float(entry['low'])},\"\n",
    "                    f\"{float(entry['close'])}\\n\"\n",
    "                )\n",
    "                ohlc_buffer.write(row)\n",
    "\n",
    "    ohlc_buffer.seek(0)\n",
    "\n",
    "    with psycopg2.connect(CONNECTION_URL) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.copy_from(\n",
    "                ohlc_buffer,\n",
    "                \"ohlc\",\n",
    "                sep=\",\",\n",
    "                columns=[\"symbol\", \"industry\", \"timestamp\", \"open\", \"high\", \"low\", \"close\"]\n",
    "            )\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "# While the code below works, it takes significantly longer\n",
    "# OHLC_DIR = os.path.join(BASE_DIR, \"OHLC\")\n",
    "\n",
    "# symbol_industry = extract_symbol_industry()\n",
    "\n",
    "# def insert_ohlc(symbol):\n",
    "#     symbol_path = os.path.join(OHLC_DIR, symbol)\n",
    "#     new_keys = {\"symbol\": symbol, \"industry\": symbol_industry[symbol]}\n",
    "#     for date in os.listdir(symbol_path):\n",
    "#         ohlc_data = []\n",
    "#         file_path = os.path.join(symbol_path, date)\n",
    "#         with gzip.open(file_path, \"rt\") as file:\n",
    "#             ohlc_data.extend(csv.DictReader(file, delimiter=\",\"))\n",
    "        \n",
    "#         ohlc_data = [{**entry, **new_keys} for entry in ohlc_data]\n",
    "        \n",
    "#         with psycopg2.connect(CONNECTION_URL) as conn:\n",
    "#             cursor = conn.cursor()\n",
    "#             psycopg2.extras.execute_batch(\n",
    "#                 cursor,\n",
    "#                 \"INSERT INTO ohlc (symbol, industry, timestamp, open, high, low, close) VALUES (%s, %s, TO_TIMESTAMP(%s), %s, %s, %s, %s)\",\n",
    "#                 [(entry[\"symbol\"], entry[\"industry\"], int(entry[\"timestamp\"]), float(entry[\"open\"]), float(entry[\"high\"]), float(entry[\"low\"]), float(entry[\"close\"])) for entry in ohlc_data],\n",
    "#                 page_size=20000  # Inserts in batches of 1000\n",
    "#             )\n",
    "#         conn.commit()\n",
    "\n",
    "# insert_ohlc(\"AAPL\") # page_size makes little to no diff, takes around 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses multiprocessing to parallelize bulk insertions\n",
    "def mp_insert_ohlc():\n",
    "    ohlc_symbols = os.listdir(OHLC_DIR)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor.map(insert_ohlc, ohlc_symbols)\n",
    "\n",
    "mp_insert_ohlc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL executed successfully.\n"
     ]
    }
   ],
   "source": [
    "def create_ohlc_hypertable():\n",
    "    db_exec(\"\"\"SELECT create_hypertable('ohlc', by_range('timestamp'), migrate_data => TRUE);\"\"\")\n",
    "\n",
    "create_ohlc_hypertable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_moving_averages(window_size='1 week', symbol='AAPL', ratio_threshold=5):\n",
    "    query = f\"\"\"\n",
    "    WITH symbol_data AS (\n",
    "        SELECT symbol, time_bucket(%s, timestamp) AS time_window, AVG(close) AS avg_close\n",
    "        FROM ohlc\n",
    "        WHERE timestamp >= '2014-01-01' AND symbol = %s\n",
    "        GROUP BY symbol, time_window\n",
    "    ),\n",
    "    moving_avg AS (\n",
    "        SELECT symbol, time_window, avg_close, LAG(avg_close) OVER (PARTITION BY symbol ORDER BY time_window) AS prev_avg_close\n",
    "        FROM symbol_data\n",
    "    )\n",
    "    SELECT \n",
    "        symbol, \n",
    "        time_window, \n",
    "        avg_close, \n",
    "        prev_avg_close, \n",
    "        (avg_close - prev_avg_close) / prev_avg_close * 100 AS percent_change\n",
    "    FROM moving_avg\n",
    "    WHERE prev_avg_close IS NOT NULL\n",
    "    AND ABS((avg_close - prev_avg_close) / prev_avg_close * 100) >= %s\n",
    "    ORDER BY symbol, time_window;\n",
    "    \"\"\"\n",
    "\n",
    "    with psycopg2.connect(CONNECTION_URL) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(query, (window_size, symbol, ratio_threshold))\n",
    "            results = cursor.fetchall()\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "results = fetch_moving_averages(window_size='1 week', symbol='AAPL', ratio_threshold=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without the use of timescaledb\n",
    "# def get_moving_averages(symbol, window=1, ratio=5, group_by_industry=False):\n",
    "#     \"\"\"\n",
    "#     Calculates moving averages for a given symbol with an optional industry grouping.\n",
    "\n",
    "#     Args:\n",
    "#         symbol (str): Stock symbol to analyze.\n",
    "#         window (int): Window size in weeks (1 or 2).\n",
    "#         ratio (int): Significant price change threshold in percentage (±5, ±10, ±15).\n",
    "#         group_by_industry (bool): If True, groups by industry instead of symbol.\n",
    "\n",
    "#     Returns:\n",
    "#         List of tuples: (symbol/industry, window_start, avg_close, prev_avg_close, price_change_percentage)\n",
    "#     \"\"\"\n",
    "#     group_column = \"industry\" if group_by_industry else \"symbol, industry\"\n",
    "#     partition_column = \"industry\" if group_by_industry else \"symbol\"\n",
    "    \n",
    "#     sql = f\"\"\"\n",
    "#     WITH ohlc_window AS (\n",
    "#         SELECT \n",
    "#             {group_column},\n",
    "#             DATE_TRUNC('week', timestamp) AS window_start,\n",
    "#             AVG(close) AS avg_close\n",
    "#         FROM ohlc\n",
    "#         WHERE symbol = %s AND timestamp >= '2014-01-01'\n",
    "#         GROUP BY {group_column}, window_start\n",
    "#     ),\n",
    "#     price_changes AS (\n",
    "#         SELECT \n",
    "#             {group_column},\n",
    "#             window_start,\n",
    "#             avg_close,\n",
    "#             LAG(avg_close) OVER (PARTITION BY {partition_column} ORDER BY window_start) AS prev_avg_close\n",
    "#         FROM ohlc_window\n",
    "#     )\n",
    "#     SELECT \n",
    "#         {group_column},\n",
    "#         window_start,\n",
    "#         avg_close,\n",
    "#         prev_avg_close,\n",
    "#         (avg_close - prev_avg_close) / prev_avg_close * 100 AS price_change_percentage\n",
    "#     FROM price_changes\n",
    "#     WHERE prev_avg_close IS NOT NULL\n",
    "#     AND ABS((avg_close - prev_avg_close) / prev_avg_close * 100) >= %s;\n",
    "#     \"\"\"\n",
    "\n",
    "#     with psycopg2.connect(CONNECTION_URL) as conn:\n",
    "#         with conn.cursor() as cursor:\n",
    "#             cursor.execute(sql, (symbol, ratio))\n",
    "#             result = cursor.fetchall()\n",
    "    \n",
    "#     return result\n",
    "\n",
    "# # Example Usage:\n",
    "# symbol = \"AAPL\"\n",
    "# window = 2  # 2-week window\n",
    "# ratio = 10  # 10% price change threshold\n",
    "# group_by_industry = False  # Set to True if you want industry-level aggregation\n",
    "\n",
    "# result = get_moving_averages(symbol, window, ratio, group_by_industry)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dataset/profile_estimate/historical_earning_estimates.json\", \"r\") as file:\n",
    "    earnings_estimate_data = json.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_moving_averge = \"\"\"\n",
    "WITH ohlc_windows AS (\n",
    "    SELECT \n",
    "        time_bucket('1 week', o.timestamp) AS window_start,  \n",
    "        s.symbol, \n",
    "        i.industry,\n",
    "        AVG(o.close) AS moving_avg,\n",
    "        LAG(AVG(o.close)) OVER (PARTITION BY s.id ORDER BY time_bucket('1 week', o.timestamp)) AS prev_moving_avg\n",
    "    FROM ohlc o\n",
    "    JOIN symbol s ON o.symbol_id = s.id\n",
    "    JOIN industry i ON s.industry_id = i.id\n",
    "    WHERE o.timestamp >= '2014-01-01'\n",
    "    GROUP BY s.id, s.symbol, i.industry, time_bucket('1 week', o.timestamp)\n",
    ")\n",
    "SELECT \n",
    "    window_start,\n",
    "    symbol,\n",
    "    industry,\n",
    "    moving_avg,\n",
    "    prev_moving_avg,\n",
    "    ((moving_avg - prev_moving_avg) / prev_moving_avg) * 100 AS percent_change\n",
    "FROM ohlc_windows\n",
    "WHERE ABS((moving_avg - prev_moving_avg) / prev_moving_avg) * 100 IN (5, 10, 15);\n",
    "\"\"\"\n",
    "db_exec(calc_moving_averge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_industry_table = \"\"\"CREATE TABLE IF NOT EXISTS industry (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(50) UNIQUE NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "db_exec(create_industry_table, \"INDUSTRY table created successfully\")\n",
    "\n",
    "create_symbol_table = \"\"\"CREATE TABLE IF NOT EXISTS symbol  (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(10) UNIQUE NOT NULL,\n",
    "    industry_id INTEGER references industry(id) ON DELETE SET NULL\n",
    ");\n",
    "\"\"\"\n",
    "db_exec(create_symbol_table, \"SYMBOL table created successfully\")\n",
    "\n",
    "create_ohlc_table = \"\"\"CREATE TABLE IF NOT EXISTS ohlc (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    symbol_id INTEGER REFERENCES symbol(id) ON DELETE CASCADE,\n",
    "    timestamp TIMESTAMP WITHOUT TIME ZONE NOT NULL,\n",
    "    open DECIMAL(10,2),\n",
    "    high DECIMAL(10,2),\n",
    "    low DECIMAL(10,2),\n",
    "    close DECIMAL(10,2),\n",
    "    volume BIGINT\n",
    ");\n",
    "\"\"\"\n",
    "db_exec(create_ohlc_table, \"OHLC table created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_industries():\n",
    "    industries = set()\n",
    "    with open(PROFILE_PATH, \"r\") as file:\n",
    "        company_profiles = json.load(file)\n",
    "        for companies in company_profiles.values():\n",
    "            industry = companies[0][\"industry\"]\n",
    "            if industry:\n",
    "                industries.add(industry)\n",
    "    return industries\n",
    "\n",
    "def insert_industries():\n",
    "    industries = extract_industries()\n",
    "    values = \", \".join([\"(%s)\"] * len(industries))\n",
    "    sql = f\"INSERT INTO industry (name) VALUES {values} ON CONFLICT (name) DO NOTHING\" # batch insertion\n",
    "    with psycopg2.connect(CONNECTION_URL) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(sql, tuple(industries))\n",
    "        conn.commit()\n",
    "\n",
    "def extract_symbols():\n",
    "    symbols = set()\n",
    "    with open(PROFILE_PATH, \"r\") as file:\n",
    "        company_profiles = json.load(file)\n",
    "        for symbol in company_profiles.keys():\n",
    "            symbols.add(symbol)\n",
    "    return symbols\n",
    "\n",
    "def insert_symbols():\n",
    "    symbols = extract_symbols()\n",
    "    values = \", \".join([\"(%s)\"] * len(symbols))\n",
    "    sql = f\"INSERT INTO symbol (name, industry_id) VALUES {values} ON CONFLICT (name) DO NOTHING;\"\n",
    "\n",
    "    industry_lookup_sql = \"SELECT id, name FROM industry;\"\n",
    "\n",
    "    with psycopg2.connect(CONNECTION_URL) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(industry_lookup_sql)\n",
    "            industry_map = {name: id for id, name in cursor.fetchall()}\n",
    "\n",
    "            params = []\n",
    "            for symbol in symbols:\n",
    "                industry_id = industry_map.get(symbol[\"industry\"])\n",
    "                if industry_id:\n",
    "                    params.extend([symbol[\"name\"], industry_id])\n",
    "\n",
    "            if params:\n",
    "                cursor.execute(sql, tuple(params))\n",
    "                conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4221-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
